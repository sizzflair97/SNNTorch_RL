{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import utils as utls\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch import utils\n",
    "from snntorch import surrogate\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/jeshraghian/snntorch/blob/master/examples/tutorial_sae.ipynb\n",
    "class SAE(torch.nn.Module):\n",
    "    def __init__(self, latent_dim, beta=0.9, spike_grad=None, threshold=1.0):\n",
    "        super().__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        if spike_grad == None: spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "        \n",
    "        self.encoder = nn.Sequential(nn.Conv2d(1, 32, 3, padding=1, stride=2),\n",
    "                                     nn.BatchNorm2d(32),\n",
    "                                     snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, threshold=threshold),\n",
    "                                     nn.Conv2d(32, 64, 3, padding=1, stride=2),\n",
    "                                     nn.BatchNorm2d(64),\n",
    "                                     snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, threshold=threshold),\n",
    "                                     nn.Conv2d(64, 128, 3, padding=1, stride=2),\n",
    "                                     nn.BatchNorm2d(128),\n",
    "                                     snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, threshold=threshold),\n",
    "                                     nn.Flatten(start_dim=1, end_dim=3),\n",
    "                                     nn.Linear(128*4*4, latent_dim),\n",
    "                                     snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True, threshold=threshold))\n",
    "        \n",
    "        # From latent back to tensor for convolution\n",
    "        self.linear_net = nn.Sequential(nn.Linear(latent_dim,128*4*4),\n",
    "                            snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True,threshold=threshold))\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(nn.Unflatten(1,(128,4,4)), #Unflatten data from 1 dim to tensor of 128 x 4 x 4\n",
    "                            snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,threshold=threshold),\n",
    "                            nn.ConvTranspose2d(128, 64, 3,padding = 1,stride=(2,2),output_padding=1),\n",
    "                            nn.BatchNorm2d(64),\n",
    "                            snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,threshold=threshold),\n",
    "                            nn.ConvTranspose2d(64, 32, 3,padding = 1,stride=(2,2),output_padding=1),\n",
    "                            nn.BatchNorm2d(32),\n",
    "                            snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,threshold=threshold),\n",
    "                            nn.ConvTranspose2d(32, 1, 3,padding = 1,stride=(2,2),output_padding=1),\n",
    "                            snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True,output=True,threshold=20000) #make large so membrane can be trained\n",
    "                            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #Reset hidden states of LIF nodes.\n",
    "        #Dim x: [Batch, Channels, Width, Length]\n",
    "        batch_size, channels, width, height = x.shape\n",
    "        for net in [self.encoder, self.linear_net, self.decoder]:\n",
    "            utils.reset(net)\n",
    "            \n",
    "        spk_mem, spk_rec, encoded_x = [], [], []\n",
    "        for step in range(num_steps:=5):\n",
    "            spk_x, mem_x = self.encoder(x) # Output spike trains and neuron membrane states\n",
    "            spk_rec.append(spk_x)\n",
    "            spk_mem.append(mem_x)\n",
    "        spk_rec = torch.stack(spk_rec, dim=2)\n",
    "        spk_mem = torch.stack(spk_mem, dim=2) #Dimensions: [Batch, Latent Dim, Time]\n",
    "\n",
    "        spk_mem2, spk_rec2, decoded_x = [], [], []\n",
    "        for step in range(num_steps):\n",
    "            x_recon, x_mem_recon = self.decode(spk_rec[:, :, step])\n",
    "            spk_rec2.append(x_recon)\n",
    "            spk_mem2.append(x_mem_recon)\n",
    "        spk_rec2 = torch.stack(spk_rec2, dim=4)\n",
    "        spk_mem2 = torch.stack(spk_mem2, dim=4) #Dimensions: [Batch, Channels, Width, Length, Time]\n",
    "        out = spk_mem2[:,:,:,:,-1]\n",
    "        return out                \n",
    "        \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, x):\n",
    "        spk_x, mem_x = self.linear_net(x)\n",
    "        spk_x2, mem_x2 = self.decoder(spk_x)\n",
    "        return spk_x2, mem_x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader arguments\n",
    "batch_size = 250\n",
    "data_path='/data/mnist'\n",
    "dtype = torch.float\n",
    "\n",
    "# Define a transform\n",
    "input_size = 32 #for the sake of this tutorial, we will be resizing the original MNIST from 28 to 32\n",
    "\n",
    "transform = transforms.Compose([\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "# Load MNIST\n",
    "\n",
    "# Training data\n",
    "train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Testing data\n",
    "test_dataset = datasets.MNIST(root='dataset/', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cortex, train_loader, optimizer, epoch, max_epoch=10):\n",
    "    cortex = cortex.train()\n",
    "    train_loss_history = []\n",
    "    \n",
    "    for batch_idx, (real_img, labels) in enumerate(pbar:=tqdm(train_loader)):\n",
    "        optimizer.zero_grad()\n",
    "        real_img = real_img.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        x_recon = cortex(real_img)\n",
    "        \n",
    "        loss = F.mse_loss(x_recon, real_img)\n",
    "        \n",
    "        pbar.desc = f'Train[{epoch:02}/{max_epoch}][{batch_idx+1:03}/{len(train_loader)}] Loss: {loss.item():.5f}'\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(cortex, test_loader, epoch, max_epoch=10):\n",
    "    cortex = cortex.eval()\n",
    "    test_loss_history = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (real_img, labels) in enumerate(pbar:=tqdm(test_loader)):\n",
    "            real_img, labels = real_img.to(device), labels.to(device)\n",
    "            x_recon = cortex(real_img)\n",
    "            \n",
    "            loss = F.mse_loss(x_recon, real_img)\n",
    "            \n",
    "            \n",
    "            pbar.desc = f'Train[{epoch:02}/{max_epoch}][{batch_idx+1:03}/{len(test_loader)}] Loss: {loss.item():.5f}'\n",
    "            \n",
    "            if batch_idx == len(test_loader)-1:\n",
    "                utls.save_image((real_img+1)/2, f'figures/testing/epoch{epoch}_finalbatch_inputs.png')\n",
    "                utls.save_image((x_recon+1)/2, f'figures/testing/epoch{epoch}_finalbatch_recons.png')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training/ and testing/ folders in your chosen path\n",
    "if not os.path.isdir('figures/training'):\n",
    "    os.makedirs('figures/training')\n",
    "    \n",
    "if not os.path.isdir('figures/testing'):\n",
    "    os.makedirs('figures/testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2119e31153de43cb8fb64f368978735c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99435fbc686c4b3ab599d99e3322f8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f710f97440cf4ca2a2629e889f31b5ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49305c4deeb4d2ba8251b8729def358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f7dbba325e430f8bd8f5af35324221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8bfca5510b46f4a00ac76124608f11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "633b2f92797c4c9b808bc88bd520ab0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a5b234421c448ebe1d961e42faf4e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53fe4c1121ba4419a665798fa653d92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a6b42a871d4403a958327ffa1298f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbba3d0ca8c4ab7afab8afb4151625c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6847f3c9c74d49e29e187e130d91f42d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff89c80d5394701bd2ca767fb9f9763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e36065e9c9434086c71cd4dc99dd50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f31f51df93945088a311bc5c8e315b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66a792176464bc99f20a8f60cfa3615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0db3d231b0a42028c8362bb0ac76334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fae0114521b4f11bb50c63ee9ed5db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229009059e1b449aa024bc040c53c154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac727a55932849009e8421265a05f302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_size = 250\n",
    "input_size = 32\n",
    "\n",
    "dtype = torch.float\n",
    "spike_grad = surrogate.atan(alpha=2)\n",
    "beta = 0.5\n",
    "num_steps = 5\n",
    "latent_dim = 32\n",
    "threshold = 1\n",
    "epochs = 10\n",
    "max_epoch = epochs\n",
    "\n",
    "cortex = SAE(latent_dim=latent_dim, beta=beta, spike_grad=spike_grad, threshold=1).to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(cortex.parameters(), lr=1e-4, betas=(0.9, 0.999), weight_decay=1e-3)\n",
    "\n",
    "for idx_epoch in range(epochs):\n",
    "    train_loss = train(cortex, train_loader=train_loader, optimizer=optimizer, epoch=idx_epoch, max_epoch=max_epoch)\n",
    "    test_loss = test(cortex, test_loader=test_loader, epoch=idx_epoch, max_epoch=max_epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

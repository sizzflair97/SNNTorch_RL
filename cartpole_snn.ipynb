{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pygame\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch import spikegen, surrogate\n",
    "from snntorch import utils as snnutils\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import utils as torchtils\n",
    "\n",
    "from typing import TypeVar, Union, List, Callable\n",
    "from torchtyping import TensorType\n",
    "\n",
    "from itertools import count, product\n",
    "from collections import deque\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.set_default_device(['cpu', 'cuda'][torch.cuda.is_available()])\n",
    "\n",
    "pygame.init()\n",
    "DISPLAYURF = pygame.display.set_mode((500,500),0,32)\n",
    "clock = pygame.time.Clock()\n",
    "pygame.display.flip()\n",
    "\n",
    "env = gym.make('CartPole-v1', render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_EligibleLeakyLinear = TypeVar(\"T_EligibleLeakyLinear\", bound=\"EligibleLeakyLinear\")\n",
    "class EligibleLeakyLinear(nn.Module):\n",
    "    def __init__(self, in_features:int, out_features:int,\n",
    "                 R=5, C=1e-3, time_step=1e-4, threshold=1.0, spike_grad=None,\n",
    "                 decay_rate:float=1.):\n",
    "        super().__init__()\n",
    "        if spike_grad == None:\n",
    "            spike_grad = surrogate.fast_sigmoid()\n",
    "        \n",
    "        self.decay_rate = decay_rate\n",
    "        self.beta = 1 - time_step/(R*C)\n",
    "        \n",
    "        # self.linear = nn.Linear(in_features, out_features, bias=False) # weight.shape == output_features by in_features\n",
    "        # self.linear:TensorType[...] = (torch.rand((out_features, in_features))+1)/(2*(in_features**.5))\n",
    "        self.linear:TensorType[...] = (torch.rand((out_features, in_features))+2)/(2)\n",
    "        # self.leaky = snn.Leaky(beta, threshold, spike_grad, init_hidden=True, output=True)\n",
    "        # self.leaky = snn.Leaky(beta, threshold, surrogate_disable=True, output=True)\n",
    "        self.leaky = snn.Lapicque(R=R, C=C, time_step=time_step, threshold=threshold)\n",
    "        # self.eligibility = torch.zeros_like((self.linear.state_dict()[\"weight\"]))\n",
    "        self.reset()\n",
    "    \n",
    "    def forward(self, presynaptic_spk:TensorType[...]):\n",
    "        spk, self.mem = self.leaky(self.linear @ presynaptic_spk, self.mem)\n",
    "        # print(self.mem)\n",
    "        return spk\n",
    "\n",
    "    def reset(self):\n",
    "        self.eligibility = torch.zeros_like(self.linear)\n",
    "        self.mem = torch.rand(self.linear.shape[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_Brain = TypeVar(\"T_Brain\", bound=\"Brain\")\n",
    "class Brain:\n",
    "    @classmethod\n",
    "    def remap_dopamine_impulse(self, x):\n",
    "        return 2*np.arctan(x)/np.pi\n",
    "    \n",
    "    def __init__(self, alpha=1e-5, R:float=5, C:float=1e-3, \n",
    "                 time_step:float=1e-4, threshold:float=1.0, spike_grad:Union[None, Callable]=None,\n",
    "                 feature_list:List=[4,32,2], obs_duration:int=8, max_queue_size:Union[int,None]=None):\n",
    "        if spike_grad == None:\n",
    "            spike_grad = surrogate.fast_sigmoid()\n",
    "            \n",
    "        self.alpha, self.threshold, self.spike_grad, self.feature_list, self.obs_duration, self.max_queue_size = \\\n",
    "            alpha, threshold, spike_grad, feature_list, obs_duration, max_queue_size\n",
    "        self.R, self.C, self.time_step = R, C, time_step\n",
    "        self.LTP_coeff, self.LTD_coeff = 1, 1.5\n",
    "        \n",
    "        self.lif_linears:List[T_EligibleLeakyLinear] = []\n",
    "        for in_features, out_features in zip(feature_list[:-1], feature_list[1:]):\n",
    "            self.lif_linears.append(\n",
    "                EligibleLeakyLinear(in_features, out_features,\n",
    "                                    R=R,    C=C,    time_step=time_step,\n",
    "                                    threshold=threshold, spike_grad=spike_grad)\n",
    "                )\n",
    "        \n",
    "        self.reset()\n",
    "    \n",
    "    def get_beta(self): return 1-self.time_step/self.R/self.C\n",
    "    \n",
    "    def step(self, x:TensorType[\"observation_space\"], dopamine_impulse:float=0., attention=False) -> TensorType[\"action_space\"]:\n",
    "        assert len(self.lif_linears) + 1 == len(self.last_spikes)\n",
    "        \n",
    "        next_spikes:List[TensorType[...]] = [x] # next_spike[0] will be provided in the next step.\n",
    "        for i, lif_linear in enumerate(self.lif_linears):\n",
    "            next_spikes.append(lif_linear(self.last_spikes[i]))\n",
    "        \n",
    "        for l, lif_linear in enumerate(self.lif_linears):\n",
    "            lif_linear.eligibility = self.get_beta() * lif_linear.eligibility \\\n",
    "                + self.alpha * self.LTP_coeff * torch.einsum(\"i,j -> ij\", next_spikes[l+1], self.last_spikes[l]) \\\n",
    "                - self.alpha * self.LTD_coeff * torch.einsum(\"i,j -> ij\", self.last_spikes[l+1], next_spikes[l])\n",
    "                # + self.LTP_coeff * torch.einsum(\"i,j -> ij\", next_spikes[l+1], next_spikes[l])\n",
    "        \n",
    "        self.dopamine = self.dopamine * self.get_beta() + dopamine_impulse\n",
    "        # print(f\"DA: {self.dopamine}\")\n",
    "        for lif_linear in self.lif_linears:\n",
    "            # print(f\"delta weight : {(lif_linear.eligibility**2).mean() * self.dopamine}\")\n",
    "            lif_linear.linear = torch.sigmoid(\n",
    "                torch.logit(lif_linear.linear * lif_linear.decay_rate, eps=1e-6)\\\n",
    "                    + lif_linear.eligibility * self.dopamine\n",
    "                )\n",
    "            # assert (lif_linear.linear<0).sum() == 0\n",
    "            \n",
    "        self.last_spikes = next_spikes\n",
    "        \n",
    "        assert next_spikes[-1].shape == (2,)\n",
    "        self.spike_history.append(next_spikes[-1])\n",
    "        return next_spikes[-1]\n",
    "    \n",
    "    def get_max_steps(self):\n",
    "        return self.obs_duration + len(self.feature_list)\n",
    "    \n",
    "    def encode(self, x:np.ndarray) -> TensorType[\"num_steps\", \"observation_space\"]:\n",
    "        pos_prob = lambda pos: pos / 9.6 + .5\n",
    "        v_prob = lambda v: np.arctan(v)/np.pi + .5\n",
    "        angle_prob = lambda theta: theta/.836 + .5\n",
    "        angle_v_prob = lambda omega: np.arctan(omega)/np.pi + .5 \n",
    "        assert len(x) == 4\n",
    "        prob_x = pos_prob(x[0]), v_prob(x[1]), angle_prob(x[2]), angle_v_prob(x[3])\n",
    "        prob_x = torch.tensor(prob_x, dtype=torch.float32)\n",
    "        return spikegen.rate(prob_x, num_steps=self.get_max_steps()) #last # of layers steps will not passed to output layer. \n",
    "    \n",
    "    def get_action(self) -> TensorType[int]:\n",
    "        action = torch.zeros((self.feature_list[-1]))\n",
    "        while len(self.spike_history) != 0:\n",
    "            # print(spike:=self.spike_history.popleft())\n",
    "            action = action * (1-1/len(self.feature_list)) + self.spike_history.popleft()\n",
    "        #     print(f\"{action}\", end=\", \")\n",
    "        # print()\n",
    "        # if action[0]!=action[1]:\n",
    "        #     print(action)\n",
    "        return action.argmax()\n",
    "    \n",
    "    def observe2action(self, x:np.ndarray, dopamine_impulse:float) -> int:\n",
    "        encoded_x = self.encode(x)\n",
    "        # print(encoded_x.mean(dim=0))\n",
    "        self.step(encoded_x[0], Brain.remap_dopamine_impulse(dopamine_impulse))\n",
    "        for step in range(1, encoded_x.shape[0]):\n",
    "            self.step(encoded_x[step])\n",
    "        action = self.get_action().item()\n",
    "        return action\n",
    "\n",
    "    def reset(self):\n",
    "        self.last_spikes:List[TensorType[...]] = [torch.zeros(n_features) for n_features in self.feature_list]\n",
    "        self.spike_history = deque([],\n",
    "            maxlen= self.obs_duration if self.max_queue_size==None else min(self.obs_duration, self.max_queue_size)\n",
    "            )\n",
    "        self.dopamine = 0.\n",
    "        for lif_linear in self.lif_linears:\n",
    "            lif_linear.reset()\n",
    "        print(\"\\r\",(self.lif_linears[0].linear**2).sum(), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(**kwargs):\n",
    "    brain = Brain(**kwargs)\n",
    "    max_t = -float(\"inf\")\n",
    "    for i_episode in (pbar:=tqdm(range(1000))):\n",
    "        observation, _ = env.reset()\n",
    "        reward, done = 0, False\n",
    "        brain.reset()\n",
    "        accm_reward = 0\n",
    "        for t in range(100):\n",
    "            image = env.render()\n",
    "            # action = env.action_space.sample()\n",
    "            action = brain.observe2action(observation, reward)\n",
    "            if done:\n",
    "                pbar.desc = f\"Timestep {kwargs.get('time_step', None)} Episode {i_episode} finished after {t+1} timesteps, with reward {accm_reward}.\"\n",
    "                break\n",
    "            \n",
    "            observation, reward, done, *info = env.step(action)\n",
    "            reward = max_t < t - done\n",
    "            accm_reward += reward\n",
    "            \n",
    "            # image = Image.fromarray(image, \"RGB\")\n",
    "            # mode, size, data = image.mode, image.size, image.tobytes()\n",
    "            # pygame.event.get()\n",
    "            # image = pygame.image.fromstring(data, size, mode)\n",
    "            \n",
    "            # DISPLAYURF.blit(image, (0,0))\n",
    "            ## print(f\"Episode {i_episode}, Step {t}, Reward {reward}\")\n",
    "            # pygame.display.update()\n",
    "            # clock.tick(100)\n",
    "        max_t = max(max_t, t)\n",
    "        if i_episode==0:\n",
    "            t_mean = t\n",
    "        else:\n",
    "            t_mean = 0.99*t_mean + 0.05*t\n",
    "    return t_mean\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tensor(203.9799, device='cuda:0')"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fd5a562b104f219528bc23864bdcca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " tensor(42.8917, device='cuda:0'))"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "# time_steps = [*np.arange(0.01, 0.1, 0.01)]\n",
    "options = {\"time_step\":[8e-5], \"alpha\":[10**(-x) for x in range(1,6)]}\n",
    "# time_steps = [*np.arange(8e-5,13e-5,1e-5)]\n",
    "options_prod = (dict(zip(options.keys(), x)) for x in product(*options.values()))\n",
    "for kwargs in options_prod:\n",
    "    result.append(test(**kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.157577955045467]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import pygame\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import snntorch as snn\n",
    "from snntorch import spikegen, surrogate\n",
    "from snntorch import utils as snnutils\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import utils as torchtils\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from typing import TypeVar, Union, List, Callable, Any, Deque\n",
    "from torchtyping import TensorType\n",
    "\n",
    "from itertools import count, product\n",
    "from collections import deque\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import logging\n",
    "from time import strftime, time, localtime\n",
    "\n",
    "import argparse\n",
    "\n",
    "torch.set_default_device(['cpu', 'cuda'][torch.cuda.is_available()])\n",
    "writer:SummaryWriter\n",
    "counter = count()\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = strftime(\"%m-%d-%H-%M\", localtime())\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', filename=\"last.log\", level=logging.INFO, datefmt='%m/%d/%Y %I:%M:%S %p')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pygame.init()\n",
    "# DISPLAYURF = pygame.display.set_mode((500,500),0,32)\n",
    "# clock = pygame.time.Clock()\n",
    "# pygame.display.flip()\n",
    "\n",
    "# env = gym.make('CartPole-v1', render_mode=\"rgb_array\")\n",
    "env = gym.make('CartPole-v1')\n",
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = [0]\n",
    "obs_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_EligibleLeakyLinear = TypeVar(\"T_EligibleLeakyLinear\", bound=\"EligibleLeakyLinear\")\n",
    "class EligibleLeakyLinear(nn.Module):\n",
    "    def __init__(self, in_features:int, out_features:int,\n",
    "                 R=5, C=1e-2, time_step=1e-3, threshold=1.0, spike_grad=None):\n",
    "        super().__init__()\n",
    "        if spike_grad == None:\n",
    "            spike_grad = surrogate.fast_sigmoid()\n",
    "        \n",
    "        self.time_step = time_step\n",
    "        self.R, self.C = R, C\n",
    "        self.in_features, self.out_features = in_features, out_features\n",
    "        # self.linear_max = 1/in_features**.5\n",
    "        self.linear_max = 5\n",
    "        \n",
    "        beta = torch.distributions.Beta(2, 2)\n",
    "        # self.linear:TensorType[...] = torch.rand((out_features, in_features))*(out_features/in_features)\n",
    "        self.linear:TensorType[...] = beta.sample((out_features, in_features)) * self.linear_max\n",
    "        self.leaky = snn.Lapicque(R=R, C=C, time_step=time_step, threshold=threshold,\n",
    "                                  reset_mechanism=\"zero\")\n",
    "        self.reset()\n",
    "    \n",
    "    @property\n",
    "    def beta(self):\n",
    "        return self.time_step/self.R/self.C\n",
    "    \n",
    "    def forward(self, presynaptic_spk:TensorType[...]):\n",
    "        spk, self.mem = self.leaky(self.linear @ presynaptic_spk, self.mem)\n",
    "        # print(self.mem)\n",
    "        return spk\n",
    "\n",
    "    def reset(self):\n",
    "        self.f_eligibility = torch.zeros_like(self.linear)\n",
    "        self.b_eligibility = torch.zeros_like(self.linear)\n",
    "        self.mem = torch.full(self.linear.shape[:1], 0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_Brain = TypeVar(\"T_Brain\", bound=\"Brain\")\n",
    "class Brain:\n",
    "    MIN_LIF_TIMESTEP = 1e-3\n",
    "    def __init__(self, lr=1e-4, R:float=5, C:float=1e-2, \n",
    "                 time_step:float=1e-3, threshold:float=1.0, spike_grad:Union[None, Callable]=None,\n",
    "                 feature_list:List=[4, 128, 2], elg_coeff=5e-1):\n",
    "        if spike_grad == None:\n",
    "            spike_grad = surrogate.fast_sigmoid()\n",
    "            \n",
    "        self.lr, self.threshold, self.spike_grad, self.feature_list, self.elg_coeff= \\\n",
    "            lr, threshold, spike_grad, feature_list, elg_coeff\n",
    "        self.R, self.C, self.time_step = R, C, time_step\n",
    "        assert self.beta < 1\n",
    "        self.LTP_coeff, self.LTD_coeff = 1., 1.5\n",
    "        \n",
    "        self.lif_linears:List[T_EligibleLeakyLinear] = []\n",
    "        for in_features, out_features in zip(feature_list[:-1], feature_list[1:]):\n",
    "            self.lif_linears.append(\n",
    "                EligibleLeakyLinear(in_features, out_features,\n",
    "                                    R=R,    C=C,    time_step=Brain.MIN_LIF_TIMESTEP,\n",
    "                                    threshold=threshold, spike_grad=spike_grad)\n",
    "                )\n",
    "        self.reset()\n",
    "    \n",
    "    def __call__(self, *args: Any, **kwds: Any) -> Any:\n",
    "        return self.observe2action(*args, **kwds)\n",
    "    \n",
    "    @property\n",
    "    def num_steps(self):\n",
    "        return int(self.time_step/Brain.MIN_LIF_TIMESTEP)\n",
    "    \n",
    "    @property\n",
    "    def beta(self):\n",
    "        return (Brain.MIN_LIF_TIMESTEP/self.R/self.C/self.num_steps)**self.elg_coeff # dt/tau ~= 1/5\n",
    "    \n",
    "    def step(self, x:TensorType[\"observation_space\"], dopamine_impulse:float=0., step_idx:int=0) -> TensorType[\"action_space\"]:\n",
    "        assert len(self.lif_linears) + 1 == len(self.spk_history[0])\n",
    "        \n",
    "        step[0] = next(counter)\n",
    "        if step[-1] == 300:\n",
    "            assert False\n",
    "        # if step[0] == 100: assert False\n",
    "        \n",
    "        next_spikes:List[TensorType[...]] = [x] # next_spike[0] will be provided in the next step.\n",
    "        for i, lif_linear in enumerate(self.lif_linears):\n",
    "            next_spikes.append(lif_linear(self.spk_history[-1][i]))\n",
    "        \n",
    "        for l, lif_linear in enumerate(self.lif_linears):\n",
    "            f_eligible_presynaptic = torch.zeros_like(self.spk_history[0][l])\n",
    "            b_eligible_postsynaptic = torch.zeros_like(self.spk_history[0][l+1])\n",
    "            for prev_spks in self.spk_history:\n",
    "                f_eligible_presynaptic = f_eligible_presynaptic * 0.5 + prev_spks[l]\n",
    "                b_eligible_postsynaptic = b_eligible_postsynaptic * 0.75 + prev_spks[l+1]\n",
    "            forward_elg = torch.outer(next_spikes[l+1], f_eligible_presynaptic)\n",
    "            backward_elg = torch.outer(b_eligible_postsynaptic, next_spikes[l])\n",
    "            # forward_elg = torch.outer(next_spikes[l+1], self.spk_history[l])\n",
    "            # backward_elg = torch.outer(self.spk_history[l+1], next_spikes[l])\n",
    "            lif_linear.f_eligibility = lif_linear.f_eligibility * self.beta + forward_elg\n",
    "            lif_linear.b_eligibility = lif_linear.b_eligibility * self.beta + backward_elg\n",
    "            # lif_linear.f_eligibility = torch.minimum(lif_linear.f_eligibility * self.beta + forward_elg, torch.tensor(1))\n",
    "            # lif_linear.b_eligibility = torch.minimum(lif_linear.b_eligibility * self.beta + backward_elg, torch.tensor(1))\n",
    "        # if step[-1]%100 == 0:\n",
    "            # writer.add_image(\"Linear-Out-Eligibility\", self.lif_linears[0].eligibility[None], step[-1])\n",
    "            # writer.add_image(\"Linear-Out\", self.lif_linears[-1].linear[None], step[-1])\n",
    "            # writer.add_image(\"forward_elg\", forward_elg[None]/torch.tensor(.1/self.time_step), step[-1])\n",
    "            # writer.add_image(\"backward_elg\", backward_elg[None], step[-1])\n",
    "        # writer.add_scalar(\"pre_ELG-F-Norm\", forward_elg.norm(), step[-1])\n",
    "        # writer.add_scalar(\"ELG-F-Norm\", self.lif_linears[-1].f_eligibility.norm(), step[-1])\n",
    "        writer.add_scalar(\"Elg[0][0,0]\", self.lif_linears[0].f_eligibility[0,0], step[-1])\n",
    "        writer.add_scalar(\"Linear[0][0,0]\", self.lif_linears[0].linear[0,0], step[-1])\n",
    "        writer.add_scalar(\"Linear[0]Mem[0]\", self.lif_linears[0].mem[0], step[-1])\n",
    "        for lif_linear in self.lif_linears:\n",
    "            if dopamine_impulse > 0:\n",
    "                lif_linear.linear += self.lr * dopamine_impulse * lif_linear.f_eligibility\\\n",
    "                                            * (1 - lif_linear.linear/lif_linear.linear_max)\n",
    "            else:\n",
    "                lif_linear.linear += self.lr * dopamine_impulse * lif_linear.b_eligibility\\\n",
    "                                            * (- lif_linear.linear/lif_linear.linear_max)\n",
    "                # f_elg_mask = lif_linear.f_eligibility>0\n",
    "                # b_elg_mask = lif_linear.b_eligibility>0\n",
    "                # delta = (self.dopamine > 0) - lif_linear.linear/(lif_linear.out_features/lif_linear.in_features)\n",
    "                # delta *= self.lr * self.dopamine\n",
    "                # lif_linear.linear += torch.where(f_elg_mask, delta * self.LTP_coeff, 0)\n",
    "                # lif_linear.linear -= torch.where(b_elg_mask, delta * self.LTD_coeff, 0)\n",
    "                # lif_linear.linear -= self.LTD_coeff * self.lr * dopamine_impulse * lif_linear.b_eligibility\\\n",
    "                #                              * lif_linear.linear/lif_linear.in_features\n",
    "                \n",
    "                # lif_linear.linear = torch.sigmoid(\n",
    "                #     torch.logit(lif_linear.linear, eps=1e-8) + self.lr * delta# sigmoid(logit(x)+1-1)\n",
    "                # )\n",
    "        \n",
    "        logger.info(str(next_spikes[-1]))\n",
    "        if step_idx + 1 >= self.num_steps:\n",
    "            self.spike_avarage += next_spikes[-1]\n",
    "        # writer.add_histogram(\"action[0]\", next_spikes[-1][0], step[-1])\n",
    "        # writer.add_histogram(\"action[1]\", next_spikes[-1][1], step[-1])\n",
    "        writer.add_scalar(\"Num-of-Spk\", sum(spk.sum() for spk in next_spikes[1:]), step[-1])\n",
    "        self.spk_history.append(next_spikes)\n",
    "        return next_spikes[-1]\n",
    "    \n",
    "    @property\n",
    "    def max_steps(self):\n",
    "        return self.num_steps + len(self.feature_list)\n",
    "    \n",
    "    def encode(self, x:np.ndarray) -> TensorType[\"num_steps\", \"observation_space\"]:\n",
    "        pos_prob = lambda pos: pos / 9.6 + .5\n",
    "        v_prob = lambda v: torch.sigmoid(torch.tensor(v)).item()\n",
    "        angle_prob = lambda theta: theta/.836 + .5\n",
    "        angle_v_prob = lambda omega: torch.sigmoid(torch.tensor(omega)).item()\n",
    "        assert len(x) == 4\n",
    "        prob_x = pos_prob(x[0]), v_prob(x[1]), angle_prob(x[2]), angle_v_prob(x[3])\n",
    "        # result = []\n",
    "        # for p in prob_x:\n",
    "        #     result.append(\n",
    "        #         spikegen.target_rate_code(rate=p, num_steps=self.max_steps, firing_pattern=\"regular\")[0]\n",
    "        #     )\n",
    "        # return torch.stack(result, dim=1)\n",
    "        prob_x = torch.tensor(prob_x, dtype=torch.float32)\n",
    "        return spikegen.rate(prob_x, num_steps=self.max_steps) #last # of layers steps will not passed to output layer. \n",
    "    \n",
    "    def get_action(self) -> TensorType[int]:\n",
    "        return self.spike_avarage.argmax()\n",
    "        # return self.spk_history[-1][-1].argmax()\n",
    "    \n",
    "    def observe2action(self, x:np.ndarray, dopamine_impulse:float) -> int:\n",
    "        encoded_x = self.encode(x)\n",
    "        obs_history.append(encoded_x)\n",
    "        self.step(encoded_x[0], Brain.remap_dopamine_impulse(dopamine_impulse), 0)\n",
    "        for step in range(1, encoded_x.shape[0]):\n",
    "            self.step(encoded_x[step], step_idx=step)\n",
    "        action = self.get_action().item()\n",
    "        return action\n",
    "\n",
    "    def reset(self):\n",
    "        self.spk_history:Deque[List[TensorType[...]]] = deque([[torch.zeros(n_features) for n_features in self.feature_list]], maxlen=7)\n",
    "        self.spike_avarage = torch.zeros(self.feature_list[-1])\n",
    "        self.dopamine = 0.\n",
    "        for lif_linear in self.lif_linears:\n",
    "            lif_linear.reset()\n",
    "        writer.add_scalar(\"F-Norm\", self.lif_linears[0].linear.norm(), step[-1])\n",
    "    \n",
    "    @staticmethod\n",
    "    def remap_dopamine_impulse(x):\n",
    "        \"\"\"dopamine in [-1, 1].\"\"\"\n",
    "        # return 2*np.arctan(x)/np.pi\n",
    "        return min(max(x, 0), 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def inv_softplus(x):\n",
    "        return torch.log(torch.exp(x) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(alpha = 0.99, **kwargs):\n",
    "    brain = Brain(**kwargs)\n",
    "    max_t = -float(\"inf\")\n",
    "    # current_reward_multiplier = 1\n",
    "    # current_punishment_multiplier = 1\n",
    "    for i_episode in (pbar:=tqdm(range(1000))):\n",
    "        observation, _ = env.reset()\n",
    "        brain.reset()\n",
    "        reward, done = 0, False\n",
    "        accm_reward = 0\n",
    "        for t in range(100):\n",
    "            # image = env.render()\n",
    "            # action = env.action_space.sample()\n",
    "            action = brain(observation, reward)\n",
    "            if done:\n",
    "                pbar.desc = f\"time_step {kwargs.get('time_step', None)} Episode {i_episode} finished after {t} time_steps, with reward {accm_reward}.\"\n",
    "                break\n",
    "            \n",
    "            observation, reward, done, *info = env.step(action)\n",
    "            # reward = 1 + (max_t <= t) - 3*done\n",
    "            # reward = max(t-8, 0) - 1*done\n",
    "            reward = .1 if not done else -1\n",
    "            accm_reward += reward\n",
    "            \n",
    "            # image = Image.fromarray(image, \"RGB\")\n",
    "            # mode, size, data = image.mode, image.size, image.tobytes()\n",
    "            # pygame.event.get()\n",
    "            # image = pygame.image.fromstring(data, size, mode)\n",
    "            \n",
    "            # DISPLAYURF.blit(image, (0,0))\n",
    "            ## print(f\"Episode {i_episode}, Step {t}, Reward {reward}\")\n",
    "            # pygame.display.update()\n",
    "            # clock.tick(100)\n",
    "        max_t = max(max_t, t)\n",
    "        if i_episode==0:\n",
    "            t_mean = t\n",
    "        else:\n",
    "            t_mean = alpha*t_mean + (1-alpha)*t\n",
    "        writer.add_histogram(\"Step\", t, i_episode)\n",
    "        writer.add_scalar(\"Max-Step\", max_t, i_episode)\n",
    "        writer.add_scalar(\"Episode-Reward\", accm_reward, i_episode)\n",
    "    logging.info(f\"test about f{kwargs}: mean {t_mean}\")\n",
    "    \n",
    "    return t_mean\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--time_step\", action=\"store\", type=float, required=True)\n",
    "parser.add_argument(\"--elg_coeff\", action=\"store\", type=float, required=True)\n",
    "parser.add_argument(\"--alpha\", action=\"store\", default=1e-4, type=float, required=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    options = vars(parser.parse_args())\n",
    "except:\n",
    "    options = {\"time_step\":1e-1, \"alpha\":1e-2, \"lr\":1e-1, \"elg_coeff\":1e-2}\n",
    "writer = SummaryWriter(max_queue=100000, comment=str(options))\n",
    "print(options)\n",
    "logger.info(options)\n",
    "test(**options)\n",
    "    # options = {\"time_step\":[*np.arange(1e-5, 13e-5, 1e-5)], \"alpha\":[1e-5, 3e-5]}\n",
    "    # options = {\"time_step\":[*np.arange(1e-5, 13e-5, 1e-5)], \"alpha\":[1e-4, 3e-4]}\n",
    "    # options = {\"time_step\":[*np.arange(1e-5, 13e-5, 1e-5)], \"alpha\":[1e-3, 3e-3]}\n",
    "    # options = {\"time_step\":[*np.arange(1e-5, 13e-5, 1e-5)], \"alpha\":[1e-2, 3e-2]}\n",
    "    # time_steps = [*np.arange(8e-5,13e-5,1e-5)]\n",
    "\n",
    "    # options = (dict(zip(options.keys(), x)) for x in product(*options.values()))\n",
    "    # for kwargs in options:\n",
    "    #     test(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()\n",
    "env.close()\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from snntorch import spikeplot as splt\n",
    "# from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# fig.set_size_inches(15, 4)\n",
    "# ax = fig.add_subplot(111)\n",
    "# total_history = torch.concat(obs_history[:4], dim=0)\n",
    "# splt.raster(total_history, ax, s=.5, alpha=1)\n",
    "# ax.plot()\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
